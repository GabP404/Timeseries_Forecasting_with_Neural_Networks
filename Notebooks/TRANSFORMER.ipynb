{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQOpa61Thn_p"
      },
      "source": [
        "# **PARAMS**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1CDwGAKhnDX"
      },
      "outputs": [],
      "source": [
        "WINDOW_SIZE = 200\n",
        "STRIDE_SIZE = 10\n",
        "TELESCOPE_SIZE = 18\n",
        "\n",
        "TEST_QUOTA = 0.2\n",
        "VALIDATION_QUOTA = 0.15\n",
        "\n",
        "EPOCHS = 250\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "MODEL_NAME = \"TRANSFORMER\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvg8aC4LTr-H"
      },
      "source": [
        "# **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsQtLgs5T3Ho",
        "outputId": "b318488a-1aa5-4563-8d37-75dfb7bc1949"
      },
      "outputs": [],
      "source": [
        "# Fix randomness and hide warnings\n",
        "seed = 42\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "from datetime import date\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "\n",
        "import logging\n",
        "\n",
        "import random\n",
        "random.seed(seed)\n",
        "\n",
        "import math\n",
        "\n",
        "# Import tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "print(tf.__version__)\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', size=16)\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ass3Qpi6UB0Y"
      },
      "source": [
        "# **Load the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INPNstHJUEeh"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "    training_data = np.load(\"Dataset/training_data.npy\")\n",
        "    print(f\"Training shape: {training_data.shape}\")\n",
        "\n",
        "    categories = np.load(\"Dataset/categories.npy\")\n",
        "    print(f\"Categories shape: { categories.shape}\" )\n",
        "\n",
        "    valid_periods = np.load(\"Dataset/valid_periods.npy\")\n",
        "    print(f\"Valid_periods shape: { valid_periods.shape}\")\n",
        "\n",
        "    return training_data, categories, valid_periods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXwY-dBzUZrp",
        "outputId": "c8a7f44f-b8ea-43a2-f4c6-f29e25a95f1a"
      },
      "outputs": [],
      "source": [
        "training_data, categories, valid_periods = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCalGMl-j6P5"
      },
      "outputs": [],
      "source": [
        "lengths = valid_periods[:,1] - valid_periods[:,0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKX39qTdkfoo"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "df[\"Lengths\"] = lengths\n",
        "df[\"Categories\"] = categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pno1N3FblbCf"
      },
      "outputs": [],
      "source": [
        "def plotDataLengths(df):\n",
        "\n",
        "  plt.figure(figsize=(17,4))\n",
        "\n",
        "  plt.scatter(df[\"Lengths\"], df[\"Categories\"])\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Fy23y3lEl5Md",
        "outputId": "614e1e7e-3e6d-46f4-ff07-91d7089f876d"
      },
      "outputs": [],
      "source": [
        "plotDataLengths(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqM0dwm5mN-L"
      },
      "outputs": [],
      "source": [
        "del df\n",
        "del lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wand81UXUilR"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL4MXqfrUxiB",
        "outputId": "308b2af6-c15f-4c54-8d02-06b9391525c2"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UT12k5iU1OtV"
      },
      "outputs": [],
      "source": [
        "def getSequenceFromDataset(index):\n",
        "  return training_data[index,valid_periods[index][0] : valid_periods[index][1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mur6Y0p1gmv",
        "outputId": "063c1d63-428a-4657-8ad5-99c63c947d06"
      },
      "outputs": [],
      "source": [
        "getSequenceFromDataset(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBb_t9WiDSI1"
      },
      "source": [
        "# **GET ONE HOT CATEGORIES**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kWC3T-QDVn2",
        "outputId": "6ff51749-840d-489c-eea3-99bbe6787ed6"
      },
      "outputs": [],
      "source": [
        "categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWfZd1YlEV6r",
        "outputId": "866fcb06-9e31-4ff2-8c1d-cef323d673de"
      },
      "outputs": [],
      "source": [
        "np.unique(categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2dYUjt0EXyO",
        "outputId": "bea985ac-220c-4379-ef6a-c693234e1370"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary to map categories to numerical values\n",
        "category_to_index = {category: index for index, category in enumerate(np.unique(categories))}\n",
        "category_to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIevYkd2Eb_R",
        "outputId": "73c72673-9a2a-4a3c-cc7a-1d0dde07e283"
      },
      "outputs": [],
      "source": [
        "# Convert labels to numerical values using the dictionary\n",
        "numerical_labels = [category_to_index[label] for label in categories]\n",
        "numerical_labels[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZR4pkTMqFE9S"
      },
      "outputs": [],
      "source": [
        "one_hot_categories = tfk.utils.to_categorical(numerical_labels,len(np.unique(categories)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmJQqQpHFzNH",
        "outputId": "3f2067f6-38f4-48c8-a507-aaef93079bbe"
      },
      "outputs": [],
      "source": [
        "one_hot_categories[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SPvNBuDcZlz"
      },
      "source": [
        "# **Some Plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "LwWcscU2WbMi",
        "outputId": "5085023a-1766-490e-96ed-5ee1e47f8bd0"
      },
      "outputs": [],
      "source": [
        "def inspect_dataset(indexes):\n",
        "    num_plots = len(indexes)\n",
        "    fig, axs = plt.subplots(num_plots, 1, figsize=(10, 6*num_plots))\n",
        "\n",
        "    for i, index in enumerate(indexes):\n",
        "\n",
        "\n",
        "        sequence = getSequenceFromDataset(index)  # Slice the sequence using iloc\n",
        "\n",
        "        if num_plots > 1:\n",
        "            ax = axs[i]\n",
        "        else:\n",
        "            ax = axs  # If only one plot, axs is a single axis, not an array\n",
        "\n",
        "        ax.set_title(f\"Sequence {index}, Category {categories[index]}\")\n",
        "        ax.plot(sequence)  # Plot the entire sequence\n",
        "        ax.set_xlabel(\"Time\")\n",
        "        ax.set_ylabel(\"Value\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function with the DataFrame and a list of indexes of the sequences you want to plot\n",
        "inspect_dataset([3, 12500, 25000])  # Example: plotting sequences with indexes 3, 5, and 7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDzBebaOcUFB"
      },
      "source": [
        "# **Normalize and Split the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqiBV6EvcqiY",
        "outputId": "a5ac7df1-bdcc-4e4a-836a-32df6d7676d0"
      },
      "outputs": [],
      "source": [
        "test_quota = TEST_QUOTA\n",
        "test_quota"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCESNm8PRuK4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Creating indices for splitting\n",
        "indices = np.arange(len(training_data))\n",
        "\n",
        "# Splitting indices into train and test indices\n",
        "train_indices, test_indices = train_test_split(indices, test_size=test_quota, stratify=categories, random_state=seed)\n",
        "\n",
        "# Extracting data based on the split indices\n",
        "train_data = training_data[train_indices]\n",
        "test_data = training_data[test_indices]\n",
        "train_categories = categories[train_indices]\n",
        "test_categories = categories[test_indices]\n",
        "valid_periods_train = valid_periods[train_indices]\n",
        "valid_periods_test = valid_periods[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkGaqBN1WhTD",
        "outputId": "e128f979-1dc7-41ad-ddd8-0f8ed1a00a6a"
      },
      "outputs": [],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL8gUNJSWkbM",
        "outputId": "f5247d33-bbbd-414b-b9e5-fc16a0ed50f6"
      },
      "outputs": [],
      "source": [
        "test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J95nRCa3WmHS",
        "outputId": "686d8b54-ca1c-43bc-f6f5-593c98a14a51"
      },
      "outputs": [],
      "source": [
        "training_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL5VPIQa2YrS"
      },
      "outputs": [],
      "source": [
        "def getTrainSequenceFromDataset(index):\n",
        "  return train_data[index,valid_periods_train[index][0] : valid_periods_train[index][1]]\n",
        "\n",
        "def getTestSequenceFromDataset(index):\n",
        "  return test_data[index,valid_periods_test[index][0] : valid_periods_test[index][1]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lRmRp_y3Mhi",
        "outputId": "35dedee4-1b56-48aa-a491-27b1e83ccb90"
      },
      "outputs": [],
      "source": [
        "getTrainSequenceFromDataset(0).shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgJG6cxa34np",
        "outputId": "bfc9cc54-e57a-4625-a5fc-3165bca6e37d"
      },
      "outputs": [],
      "source": [
        "getTestSequenceFromDataset(0).shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "lwX_YX1Zk7VD",
        "outputId": "ae8a8e54-e3e2-4e6f-c9ac-dbbb06a045fe"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "index_to_plot = 100\n",
        "\n",
        "# Assuming X_train_raw and X_test_raw are NumPy arrays\n",
        "plt.figure(figsize=(17, 5))\n",
        "\n",
        "# Plot X_train_raw in blue color\n",
        "plt.plot(getTrainSequenceFromDataset(index_to_plot), label='Train sequence (normalized)', color='blue')\n",
        "\n",
        "\n",
        "plt.title(f'SEQUENCE {index_to_plot}: Category: {train_categories[index_to_plot]}')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9T4zumap3-D"
      },
      "source": [
        "# **Prepare the Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0Cee7mVp2zu"
      },
      "outputs": [],
      "source": [
        "window = WINDOW_SIZE\n",
        "stride = STRIDE_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BAd0uJZreYw",
        "outputId": "d115d7ac-615c-4a2e-b1cd-1e289baef69f"
      },
      "outputs": [],
      "source": [
        "future = train_data[:,-window:]\n",
        "\n",
        "print(f\"future has {future[123].shape} sequences\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogYR3JsCqBjr",
        "outputId": "c3ae7ec6-945a-4c98-8601-0c35b3f50949"
      },
      "outputs": [],
      "source": [
        "future = np.expand_dims(future, axis=0)\n",
        "future.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR3-nLSFsLz1"
      },
      "outputs": [],
      "source": [
        "def build_sequences(train=True, window=200, stride=20, telescope=100):\n",
        "    # Sanity check to avoid runtime errors\n",
        "    assert window % stride == 0\n",
        "    dataset = []\n",
        "    labels = []\n",
        "\n",
        "    maxIndex = train_data.shape[0] if train==True else test_data.shape[0]\n",
        "\n",
        "    for index in range(maxIndex):\n",
        "\n",
        "      if train == True:\n",
        "        sequence = getTrainSequenceFromDataset(index)\n",
        "        temp_sequence = getTrainSequenceFromDataset(index).copy()\n",
        "      else:\n",
        "        sequence = getTestSequenceFromDataset(index)\n",
        "        temp_sequence = getTestSequenceFromDataset(index).copy()\n",
        "\n",
        "      temp_label = sequence.copy()\n",
        "\n",
        "      padding_check = len(sequence)%window\n",
        "\n",
        "      if(padding_check != 0):\n",
        "        # Compute padding length\n",
        "        padding_len = window - len(sequence)%window\n",
        "        padding = np.zeros((padding_len), dtype='float32')\n",
        "        temp_sequence = np.concatenate((padding,sequence))\n",
        "        padding = np.zeros((padding_len), dtype='float32')\n",
        "        temp_label = np.concatenate((padding,temp_label))\n",
        "        assert len(temp_sequence) % window == 0\n",
        "\n",
        "      for idx in np.arange(0,len(temp_sequence)-window-telescope,stride):\n",
        "        dataset.append(temp_sequence[idx:idx+window])\n",
        "        labels.append(temp_label[idx+window:idx+window+telescope])\n",
        "\n",
        "      del sequence\n",
        "      del temp_sequence\n",
        "      del temp_label\n",
        "\n",
        "    dataset = np.array(dataset)\n",
        "    labels = np.array(labels)\n",
        "    return dataset, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfxSPq69yj9L"
      },
      "outputs": [],
      "source": [
        "telescope = TELESCOPE_SIZE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlqJ_q_Gy5sC"
      },
      "source": [
        "# **FORECAST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH2QR0lQy73i"
      },
      "outputs": [],
      "source": [
        "direct_telescope = telescope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5VKo11oR4es",
        "outputId": "9fb0c6f9-d6f3-466e-92ba-abecb84f3416"
      },
      "outputs": [],
      "source": [
        "stride"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcTciwFEBQts"
      },
      "outputs": [],
      "source": [
        "from keras import Layer\n",
        "\n",
        "class Time2Vector(Layer):\n",
        "  def __init__(self, seq_len, **kwargs):\n",
        "    super(Time2Vector, self).__init__()\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.weights_linear = self.add_weight(name='weight_linear',\n",
        "                                shape=(int(self.seq_len),),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "    \n",
        "    self.bias_linear = self.add_weight(name='bias_linear',\n",
        "                                shape=(int(self.seq_len),),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "    \n",
        "    self.weights_periodic = self.add_weight(name='weight_periodic',\n",
        "                                shape=(int(self.seq_len),),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "\n",
        "    self.bias_periodic = self.add_weight(name='bias_periodic',\n",
        "                                shape=(int(self.seq_len),),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "\n",
        "  def call(self, x):\n",
        "    #x = tf.math.reduce_mean(x[:,:,:4], axis=-1) # Convert (batch, seq_len, 5) to (batch, seq_len)\n",
        "    time_linear = self.weights_linear * x + self.bias_linear\n",
        "    time_linear = tf.expand_dims(time_linear, axis=-1) # (batch, seq_len, 1)\n",
        "    \n",
        "    time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
        "    time_periodic = tf.expand_dims(time_periodic, axis=-1) # (batch, seq_len, 1)\n",
        "    return tf.concat([time_linear, time_periodic], axis=-1) # (batch, seq_len, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SingleAttention(Layer):\n",
        "  def __init__(self, d_k, d_v):\n",
        "    super(SingleAttention, self).__init__()\n",
        "    self.d_k = d_k\n",
        "    self.d_v = d_v\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.query = tfkl.Dense(self.d_k, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
        "    self.key = tfkl.Dense(self.d_k, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
        "    self.value = tfkl.Dense(self.d_v, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
        "    q = self.query(inputs[0])\n",
        "    k = self.key(inputs[1])\n",
        "\n",
        "    attn_weights = tf.matmul(q, k, transpose_b=True)\n",
        "    attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
        "    attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
        "    \n",
        "    v = self.value(inputs[2])\n",
        "    attn_out = tf.matmul(attn_weights, v)\n",
        "    return attn_out  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiAttention(Layer):\n",
        "  def __init__(self, d_k, d_v, n_heads):\n",
        "    super(MultiAttention, self).__init__()\n",
        "    self.d_k = d_k\n",
        "    self.d_v = d_v\n",
        "    self.n_heads = n_heads\n",
        "    self.attn_heads = list()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    for n in range(self.n_heads):\n",
        "      self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  \n",
        "    self.linear = tfkl.Dense(3, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
        "    concat_attn = tf.concat(attn, axis=-1)\n",
        "    multi_linear = self.linear(concat_attn)\n",
        "    return multi_linear "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformerEncoder(Layer):\n",
        "  def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
        "    super(TransformerEncoder, self).__init__()\n",
        "    self.d_k = d_k\n",
        "    self.d_v = d_v\n",
        "    self.n_heads = n_heads\n",
        "    self.ff_dim = ff_dim\n",
        "    self.attn_heads = list()\n",
        "    self.dropout_rate = dropout\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
        "    self.attn_dropout = tfkl.Dropout(self.dropout_rate)\n",
        "    self.attn_normalize = tfkl.LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
        "\n",
        "    self.ff_conv1D_1 = tfkl.Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
        "    self.ff_conv1D_2 = tfkl.Conv1D(filters=3, kernel_size=1) # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1]=7 \n",
        "    self.ff_dropout = tfkl.Dropout(self.dropout_rate)\n",
        "    self.ff_normalize = tfkl.LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n",
        "  \n",
        "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
        "    attn_layer = self.attn_multi(inputs)\n",
        "    attn_layer = self.attn_dropout(attn_layer)\n",
        "    attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
        "\n",
        "    ff_layer = self.ff_conv1D_1(attn_layer)\n",
        "    ff_layer = self.ff_conv1D_2(ff_layer)\n",
        "    ff_layer = self.ff_dropout(ff_layer)\n",
        "    ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
        "    return ff_layer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExpandLayer(Layer):\n",
        "    def call(self, x):\n",
        "        return tf.expand_dims(x, axis=-1) # (batch, seq_len, 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seq_len = window\n",
        "n_output = telescope\n",
        "\n",
        "d_k = 32\n",
        "d_v = 32\n",
        "n_heads = 64\n",
        "ff_dim = 64\n",
        "\n",
        "\n",
        "def create_model():\n",
        "  '''Initialize time and transformer layers'''\n",
        "  time_embedding = Time2Vector(seq_len)\n",
        "  attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "  attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "  attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "\n",
        "  '''Construct model'''\n",
        "  in_seq = tfkl.Input(shape=(seq_len,))\n",
        "\n",
        "  x = time_embedding(in_seq)\n",
        "\n",
        "  expanded = ExpandLayer()(in_seq)\n",
        "  x = tfkl.Concatenate(axis=-1)([expanded, x])\n",
        "  x = attn_layer1((x, x, x))\n",
        "  x = attn_layer2((x, x, x))\n",
        "  x = attn_layer3((x, x, x))\n",
        "  x = tfkl.GlobalAveragePooling1D(data_format='channels_first')(x)\n",
        "  x = tfkl.Dropout(0.1)(x)\n",
        "  x = tfkl.Dense(64, activation='relu')(x)\n",
        "  x = tfkl.Dropout(0.1)(x)\n",
        "  out = tfkl.Dense(n_output, activation='linear')(x)\n",
        "\n",
        "  model = tfk.Model(inputs=in_seq, outputs=out)\n",
        "  model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mape'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "model.summary()\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = EPOCHS\n",
        "batch_size = BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SphDijMYH4G"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = build_sequences(True,window, stride, telescope)\n",
        "#X_test, y_test = build_sequences(False,window, stride, autoregressive_telescope)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaMbkV1WYH4G"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "output_shape = y_train.shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyJgd8RHYH4H",
        "outputId": "61d5e4d0-f30c-4356-e878-4400578ab064"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    batch_size = 128,\n",
        "    epochs = 250,\n",
        "    validation_split=.1,\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=15, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.1, min_lr=1e-5)\n",
        "    ]\n",
        ").history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb4z3rQkYH4H",
        "outputId": "befd2fc0-d6e7-404c-cb94-bb929807a1c0"
      },
      "outputs": [],
      "source": [
        "best_epoch = np.argmin(history['val_loss'])\n",
        "plt.figure(figsize=(17,4))\n",
        "plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.title('Mean Squared Error')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(18,3))\n",
        "plt.plot(history['learning_rate'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur1bjrLoYH4I"
      },
      "outputs": [],
      "source": [
        "model.save(\"Transformer.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr-o92tnrJd_",
        "outputId": "b8da2a7c-8863-48b7-ee34-435919d9aa7c"
      },
      "outputs": [],
      "source": [
        "X_test_reg, y_test_reg = build_sequences(False,window, stride, telescope)\n",
        "X_test_reg.shape, y_test_reg.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFTuabz6YH4I"
      },
      "outputs": [],
      "source": [
        "# Prediction\n",
        "predictions = model.predict(X_test_reg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk_8y90lYH4I",
        "outputId": "d434d98e-f668-422c-b5c9-e1f3f5156222"
      },
      "outputs": [],
      "source": [
        "# Print the shape of the predictions\n",
        "print(f\"Predictions shape: {predictions.shape}\")\n",
        "\n",
        "# Calculate and print Mean Squared Error (MSE)\n",
        "mean_squared_error = tfk.metrics.mean_squared_error(y_test_reg.flatten(), predictions.flatten()).numpy()\n",
        "print(f\"Mean Squared Error: {mean_squared_error}\")\n",
        "\n",
        "# Calculate and print Mean Absolute Error (MAE)\n",
        "mean_absolute_error = tfk.metrics.mean_absolute_error(y_test_reg.flatten(), predictions.flatten()).numpy()\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "cQOpa61Thn_p",
        "NeGJYThMTf1F",
        "pvg8aC4LTr-H",
        "fBb_t9WiDSI1",
        "0SPvNBuDcZlz"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
